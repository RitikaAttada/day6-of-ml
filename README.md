🌱 Day 6 of My Machine Learning Journey  
Welcome to Day 6 of my Machine Learning journey! 🧠  
Today, I explored **Multivariable Regression** using TensorFlow and Keras, focusing on learning equations with **two input variables (X and Z)**.

---

🧠 What I Did  
✅ Learned how to model multivariable functions using neural networks  
✅ Used `np.meshgrid()` to generate 2D datasets for regression  
✅ Applied activation functions like `tanh`, `relu`, and `sigmoid` for non-linear surfaces  
✅ Visualized loss curves and predicted vs actual plots  
✅ Saved and reused models with `.keras` format

---

📊 Problems I Solved

| # | Equation                                               | Type             |
|--:|--------------------------------------------------------|------------------|
| 1 | `Y = 4X + 5Z + 2`                                      | Linear           |
| 2 | `Y = X² + Z²`                                          | Quadratic        |
| 3 | `Y = 2sin(X) + 3cos(Z)`                                | Trigonometric    |
| 4 | `Y = e^(-0.1(X² + Z²))`                                | Exponential Decay|
| 5 | `Y = X * Z + 20`                                       | Multiplicative   |

---

🛠️ Tools Used  
- TensorFlow / Keras  
- NumPy  
- Matplotlib  
- Python 3.10+

---

📚 What I Learned  
- How to handle multiple inputs in regression  
- Importance of normalization for model stability  
- Choosing the right activation for non-linear behavior  
- How to structure and reuse ML models efficiently

---
