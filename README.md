ğŸŒ± Day 6 of My Machine Learning Journey  
Welcome to Day 6 of my Machine Learning journey! ğŸ§   
Today, I explored **Multivariable Regression** using TensorFlow and Keras, focusing on learning equations with **two input variables (X and Z)**.

---

ğŸ§  What I Did  
âœ… Learned how to model multivariable functions using neural networks  
âœ… Used `np.meshgrid()` to generate 2D datasets for regression  
âœ… Applied activation functions like `tanh`, `relu`, and `sigmoid` for non-linear surfaces  
âœ… Visualized loss curves and predicted vs actual plots  
âœ… Saved and reused models with `.keras` format

---

ğŸ“Š Problems I Solved

| # | Equation                                               | Type             |
|--:|--------------------------------------------------------|------------------|
| 1 | `Y = 4X + 5Z + 2`                                      | Linear           |
| 2 | `Y = XÂ² + ZÂ²`                                          | Quadratic        |
| 3 | `Y = 2sin(X) + 3cos(Z)`                                | Trigonometric    |
| 4 | `Y = e^(-0.1(XÂ² + ZÂ²))`                                | Exponential Decay|
| 5 | `Y = X * Z + 20`                                       | Multiplicative   |

---

ğŸ› ï¸ Tools Used  
- TensorFlow / Keras  
- NumPy  
- Matplotlib  
- Python 3.10+

---

ğŸ“š What I Learned  
- How to handle multiple inputs in regression  
- Importance of normalization for model stability  
- Choosing the right activation for non-linear behavior  
- How to structure and reuse ML models efficiently

---
